{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f3485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='keys.env')\n",
    "\n",
    "APP_ID = os.environ.get(\"APP_ID\")\n",
    "APP_KEY = os.environ.get(\"APP_KEY\")\n",
    "\n",
    "# Par√°metros generales\n",
    "\n",
    "COUNTRY = 'us'\n",
    "RESULTS_PER_PAGE = 50\n",
    "SAVE_INTERVAL = 10000\n",
    "MAX_PAGES = 1000\n",
    "MAX_EMPTY_PAGES = 10  # M√°ximo de p√°ginas sin recoger ofertas antes de saltar\n",
    "DELAY = 1\n",
    "\n",
    "locations = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \n",
    "    \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \n",
    "    \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \n",
    "    \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \n",
    "    \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "filename = \"it_jobs.csv\"\n",
    "processed_job_ids = set()\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            processed_job_ids.add(row[\"id\"])\n",
    "\n",
    "def guardar_empleos(jobs):\n",
    "    if not jobs:\n",
    "        return\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=jobs[0].keys())\n",
    "        if f.tell() == 0:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(jobs)\n",
    "\n",
    "for location in locations:\n",
    "    print(f\"\\nüåç Buscando trabajos en {location}...\")\n",
    "    current_page = 1\n",
    "    paginas_sin_resultados = 0\n",
    "    local_jobs = []\n",
    "\n",
    "    while current_page <= MAX_PAGES:\n",
    "        print(f\"üìÑ P√°gina {current_page} - {location} - Acumulado local: {len(local_jobs)}\")\n",
    "        url = f\"https://api.adzuna.com/v1/api/jobs/{COUNTRY}/search/{current_page}\"\n",
    "        params = {\n",
    "            'app_id': APP_ID,\n",
    "            'app_key': APP_KEY,\n",
    "            'category': 'it-jobs',\n",
    "            'results_per_page': RESULTS_PER_PAGE,\n",
    "            'where': location,\n",
    "            'content-type': 'application/json'\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ùå Error {response.status_code} en p√°gina {current_page} ({location})\")\n",
    "                break\n",
    "\n",
    "            data = response.json()\n",
    "            results = data.get(\"results\", [])\n",
    "\n",
    "            nuevos_trabajos = 0\n",
    "            for job in results:\n",
    "                job_id = job.get(\"id\")\n",
    "                if job_id in processed_job_ids:\n",
    "                    continue\n",
    "                processed_job_ids.add(job_id)\n",
    "                nuevos_trabajos += 1\n",
    "\n",
    "                loc = job.get(\"location\", {})\n",
    "                comp = job.get(\"company\", {})\n",
    "                cat = job.get(\"category\", {})\n",
    "\n",
    "                local_jobs.append({\n",
    "                    \"id\": job_id,\n",
    "                    \"title\": job.get(\"title\"),\n",
    "                    \"description\": job.get(\"description\"),\n",
    "                    \"location_area\": \", \".join(loc.get(\"area\", [])),\n",
    "                    \"company_display_name\": comp.get(\"display_name\"),\n",
    "                    \"category_tag\": cat.get(\"tag\"),\n",
    "                    \"contract_time\": job.get(\"contract_time\"),\n",
    "                    \"salary_min\": job.get(\"salary_min\"),\n",
    "                    \"salary_max\": job.get(\"salary_max\"),\n",
    "                    \"salary_is_predicted\": job.get(\"salary_is_predicted\"),\n",
    "                    \"created\": job.get(\"created\"),\n",
    "                    \"latitude\": job.get(\"latitude\"),\n",
    "                    \"longitude\": job.get(\"longitude\"),\n",
    "                    \"redirect_url\": job.get(\"redirect_url\"),\n",
    "                })\n",
    "\n",
    "            if nuevos_trabajos == 0:\n",
    "                paginas_sin_resultados += 1\n",
    "            else:\n",
    "                paginas_sin_resultados = 0\n",
    "\n",
    "            if paginas_sin_resultados >= MAX_EMPTY_PAGES:\n",
    "                print(f\"‚ö†Ô∏è {MAX_EMPTY_PAGES} p√°ginas sin trabajos nuevos. Pasando a la siguiente ubicaci√≥n.\")\n",
    "                break\n",
    "\n",
    "            if len(local_jobs) >= SAVE_INTERVAL:\n",
    "                guardar_empleos(local_jobs)\n",
    "                print(f\"üíæ Guardado parcial de {len(local_jobs)} trabajos en {location}\")\n",
    "                local_jobs.clear()\n",
    "\n",
    "            current_page += 1\n",
    "            time.sleep(DELAY)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en p√°gina {current_page} ({location}): {e}\")\n",
    "            break\n",
    "\n",
    "    if local_jobs:\n",
    "        guardar_empleos(local_jobs)\n",
    "        print(f\"‚úÖ Guardado final de {len(local_jobs)} trabajos para {location}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el CSV\n",
    "df = pd.read_csv('it_jobs.csv')\n",
    "\n",
    "# Verificar n√∫mero de filas antes del procesamiento\n",
    "original_count = len(df)\n",
    "\n",
    "# Eliminar filas con redirect_url vac√≠o o nulo\n",
    "df = df[df['redirect_url'].notna() & (df['redirect_url'].str.strip() != \"\")]\n",
    "\n",
    "# Eliminar duplicados por 'id' y 'redirect_url'\n",
    "df_clean = df.drop_duplicates(subset=['id', 'redirect_url'], keep='last')\n",
    "\n",
    "# Ver cu√°ntas filas se eliminaron\n",
    "removed = original_count - len(df_clean)\n",
    "print(f\"üßπ Se eliminaron {removed} filas (duplicadas o sin URL).\")\n",
    "\n",
    "# Guardar el DataFrame limpio\n",
    "df_clean.to_csv('it_jobs_clean.csv', index=False)\n",
    "print(\"‚úÖ Archivo limpio guardado como 'it_jobs_clean.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
